 RAPPORT D'AUDIT APPLICATIF Tracker Analyse complète · UX · UI · Fonctionnel · Performance · Sécurité · Architecture · Données · Scalabilité Date : Février 2026 · Type : Audit visuel + fonctionnel · Statut : En cours Axes audités : 8 domaines — UX, UI, Fonctionnel, Performance, Sécurité, Architecture, Données, Scalabilité 1. Introduction & Périmètre Ce rapport présente un audit applicatif complet de l'application Tracker, un outil de gestion d'inventaire, de suivi des équipements et de pilotage financier. L'audit couvre 8 axes d'évaluation complémentaires, allant de l'expérience utilisateur à la sécurité, en passant par la qualité du code et la scalabilité. Important : Certains axes (Performance, Sécurité, Architecture, Maintenabilité) ne peuvent être évalués qu'avec un accès au code source, à l'infrastructure et aux outils de monitoring. Les observations dans ces sections sont basées sur des indices visibles dans l'interface et des recommandations de bonnes pratiques. 2. Synthèse Globale Axe Domaine Score Interprétation UX UX / Ergonomie 6/10 Insuffisant — corrections nécessaires à court terme UI UI / Design System 6/10 Insuffisant — corrections nécessaires à court terme FONC Fonctionnel / Logique Métier 6/10 Insuffisant — corrections nécessaires à court terme PERF Performance À mesurer Nécessite un accès technique (code, infrastructure, outils) SEC Sécurité À mesurer Nécessite un accès technique (code, infrastructure, outils) ARCH Architecture & Code À mesurer Nécessite un accès technique (code, infrastructure, outils) DATA Données & Intégrité 5/10 Insuffisant — corrections nécessaires à court terme MAIN Maintenabilité & Scalabilité À mesurer Nécessite un accès technique (code, infrastructure, outils) Score moyen (axes mesurés) 5.8/10 3. Analyse Détaillée par Axe UX — UX / Ergonomie Critère Observation Score Priorité Clarté des parcours utilisateur Les flux principaux (attribution, approbation) sont identifiables mais comportent des redondances (wizard non contextuel, étapes inutiles selon le point d'entrée). 5/10 Haute Cohérence des interactions Les interactions varient selon les pages : certaines cartes sont cliquables, d'autres non. La carte 'Utilisateur Actuel' est statique sans indication. 5/10 Haute Gestion des états vides Les états vides sont présents (ex: 'Aucun appareil principal') mais manquent parfois de contextualisation et d'action immédiate claire. 6/10 Moyenne Feedback utilisateur Peu de feedbacks visibles lors des actions (chargement, confirmation, erreur). Les statuts 'EN ATTENTE' ne donnent pas d'information sur le blocage. 5/10 Haute Navigation & orientation La navigation latérale est claire. Le fil d'Ariane 'Retour' est présent. Le mode rétracté présente des icônes mal centrées. 7/10 Faible Accessibilité (a11y) Aucune vérification du contraste, de la navigation clavier ou des attributs ARIA n'a été possible à cette étape. À auditer spécifiquement. 4/10 Haute UI — UI / Design System Critère Observation Score Priorité Cohérence visuelle globale La charte graphique (teintes dorées/beiges) est appliquée de façon globalement cohérente. Quelques déviations sur les badges et boutons d'action. 7/10 Faible Typographie & hiérarchie La hiérarchie typographique est présente mais certains formulaires manquent de distinction entre champs primaires et secondaires. 6/10 Moyenne Composants réutilisables Les badges de statut, barres de recherche et cartes semblent réutilisés mais avec des variations non justifiées (badges présents ou absents selon la page). 5/10 Moyenne Espacement & alignement Des problèmes d'alignement sur la liste des équipements et de débordement sur la page Emplacements ont été identifiés. 5/10 Moyenne Responsive / Adaptation mobile La version mobile (nav rétractée) présente des icônes mal positionnées. L'adaptation des tableaux sur petits écrans est à vérifier. 5/10 Moyenne Cohérence des badges & statuts Les badges de statut sont incohérents : présents sur certaines fiches utilisateur, absents sur d'autres. La position du badge de quantité dans la barre de recherche varie. 4/10 Haute FONC — Fonctionnel / Logique Métier Critère Observation Score Priorité Couverture des besoins métier Les modules principaux sont présents : inventaire, utilisateurs, approbations, finances, emplacements, audit, rapports. La couverture fonctionnelle semble bonne. 7/10 Faible Logique des flux métier Le wizard d'attribution est générique et ignore le contexte d'entrée (depuis équipement ou utilisateur), créant une redondance critique dans le flux. 4/10 Haute Gestion des rôles & permissions Les rôles SuperAdmin, Admin, Manager, Employé semblent définis. La visibilité 'selon vos droits' est mentionnée. Les restrictions effectives sont à vérifier. 6/10 Moyenne Traçabilité des actions Un module Audit existe. Les dates de dernière activité sont affichées sur les utilisateurs. La traçabilité des modifications d'équipements est à approfondir. 7/10 Faible Gestion des cas limites Les équipements non assignés ou sans localisation ne génèrent pas d'alerte. Les IDs techniques sont exposés dans l'interface (dépenses). 4/10 Haute Cohérence des données affichées Des localisations 'N/A', des statuts bloqués sans explication, des fichiers sources non consultables révèlent des lacunes dans la cohérence des données présentées. 5/10 Haute PERF — Performance Critère Observation Score Priorité Temps de chargement initial Non mesurable à ce stade (audit visuel). À évaluer avec Lighthouse ou WebPageTest sur les pages principales. 0/10 Haute Performance des listes La liste des équipements (14 actifs) est limitée mais la pagination ou la virtualisation pour de grands volumes est à vérifier. 0/10 Moyenne Optimisation des requêtes API La structure des appels API (chargement en cascade, requêtes inutiles) n'est pas visible depuis l'interface. Nécessite un audit réseau. 0/10 Haute Taille & optimisation des assets À mesurer avec les outils de développeur. Les images d'équipements et avatars sont à vérifier (format, compression, lazy loading). 0/10 Moyenne Performance perçue (UX perf) Aucun skeleton loader ou indicateur de chargement progressif n'est visible sur les captures. L'expérience perçue pourrait être améliorée. 0/10 Moyenne SEC — Sécurité Critère Observation Score Priorité Authentification & sessions Un système de login existe (dates de dernier login visibles). La gestion des tokens, expiration de session et déconnexion automatique sont à auditer. 0/10 Haute Gestion des autorisations Les rôles sont définis (SuperAdmin, Admin, Manager, User). Les contrôles côté serveur (non seulement UI) sont à vérifier impérativement. 0/10 Haute Protection des données sensibles Des données financières (montants XOF, factures) et personnelles (emails, téléphones) sont affichées. Le chiffrement au repos et en transit est à vérifier. 0/10 Haute Vulnérabilités courantes (OWASP) XSS, CSRF, injection SQL, exposition d'IDs techniques (déjà identifiée) : un audit OWASP Top 10 est nécessaire. 0/10 Haute Gestion des fichiers uploadés Des documents sont uploadés (factures). La validation du type, la taille maximale et le stockage sécurisé sont à auditer. 0/10 Haute ARCH — Architecture & Code Critère Observation Score Priorité Qualité & lisibilité du code Non accessible depuis l'interface. À évaluer via revue de code (linting, conventions de nommage, complexité cyclomatique). 0/10 Haute Modularité des composants Les variations de composants similaires (barres de recherche, badges) suggèrent un manque de centralisation des composants UI. 0/10 Moyenne Gestion d'état applicatif À évaluer (Redux, Zustand, Context, etc.). La cohérence des données entre modules est à vérifier (wizard non contextuel suggère un state management partiel). 0/10 Haute Documentation technique Non évaluable sans accès au code. Un audit de la documentation (README, JSDoc, API docs) est recommandé. 0/10 Moyenne Tests automatisés Aucune information disponible. La couverture de tests (unitaires, intégration, E2E) est à mesurer. 0/10 Haute Dette technique Des incohérences d'interface (composants non standardisés, IDs techniques exposés) suggèrent une dette technique à quantifier. 0/10 Moyenne DATA — Données & Intégrité Critère Observation Score Priorité Validation des formulaires Les champs obligatoires sont marqués (*). La validation côté client est présente (placeholders incohérents identifiés). La validation côté serveur est à vérifier. 6/10 Haute Cohérence & complétude des données De nombreux champs affichent 'N/A' ou sont vides sans contrainte de complétude. Les équipements peuvent exister sans localisation ni responsable. 4/10 Haute Gestion des erreurs métier Aucun message d'erreur visible sur les captures. La gestion des erreurs de validation et des conflits de données est à tester. 5/10 Haute Import / Export de données Des fonctions Importer/Exporter sont présentes. Le format supporté, la validation à l'import et la gestion des erreurs d'import sont à auditer. 6/10 Moyenne Intégrité référentielle Que se passe-t-il si on supprime un utilisateur assigné à des équipements ? Ces cas de suppression en cascade sont critiques à vérifier. 4/10 Haute MAIN — Maintenabilité & Scalabilité Critère Observation Score Priorité Scalabilité de l'architecture À évaluer. La gestion de volumes importants d'équipements, utilisateurs et transactions financières est à tester. 0/10 Haute Monitoring & logs applicatifs Non visible depuis l'interface. La présence de logs structurés, alertes et dashboards de monitoring est à vérifier. 0/10 Haute Gestion des environnements La séparation dev/staging/production, les variables d'environnement et les processus de déploiement sont à auditer. 0/10 Haute Évolutivité du design system Les incohérences de composants actuelles suggèrent l'absence d'un design system formalisé, ce qui rendra les évolutions plus coûteuses. 0/10 Moyenne CI/CD & automatisation La présence d'une pipeline CI/CD (tests automatiques, déploiement continu) est à vérifier. 0/10 Haute 4. Plan d'Action Recommandé Les corrections sont classées par impact et effort d'implémentation estimé. Les items marqués 'Sans accès' nécessitent une revue technique approfondie. Sprint 1 — Immédiat (< 2 semaines) Réf. Action Effort Domaine #1 Wizard attribution contextuel (pré-remplissage selon point d'entrée) Moyen Fonctionnel #2 Titre de dépense lisible (supprimer l'ID technique) Faible UI #3 Fichier source de facture cliquable (voir + télécharger) Faible Fonctionnel #4 Carte 'Utilisateur Actuel' interactive Faible UX #5 Suppression des badges incohérents sur les fiches utilisateur Faible UI Sprint 2 — Court terme (2–4 semaines) Réf. Action Effort Domaine #6 Badge de quantité en position fixe dans les barres de recherche Faible UI #7 Débordement des boutons éditer/supprimer (Emplacements) Faible UI #8 Icônes nav latérale centrées en mode rétracté Faible UI #9 Historique approbations — design compact et raffiné Faible UI #10 Modification de l'avatar utilisateur Moyen UX #11 Contraintes de complétude : localisation et responsable obligatoires Moyen Données Sprint 3 — Moyen terme (1–2 mois) Réf. Action Effort Domaine #12 Formulaire nouveau collaborateur — restructuration UX Moyen UX #13 Formulaire dépense — hiérarchie visuelle des champs Moyen UX #14 Audit de sécurité complet (OWASP Top 10) Élevé Sécurité #15 Audit de performance (Lighthouse, profiling API) Moyen Performance #16 Intégrité référentielle (suppression en cascade) Élevé Données Sprint 4 — Long terme (2–4 mois) Réf. Action Effort Domaine #17 Design system formalisé (composants centralisés) Élevé Architecture #18 Tests automatisés (couverture unitaire + E2E) Élevé Architecture #19 Monitoring & logs applicatifs Élevé Scalabilité #20 Accessibilité (a11y) — audit WCAG 2.1 AA Moyen UX #21 Documentation technique complète Moyen Architecture 5. Conclusion Points forts Identité visuelle cohérente et charte graphique appliquée. Couverture fonctionnelle large (inventaire, finances, approbations, audit, rapports). Structure de navigation claire et hiérarchie d'information globalement bien organisée. Présence de mécanismes de traçabilité (logs d'activité, dates de connexion). Points d'amélioration prioritaires La logique de flux (wizard d'attribution non contextuel) nuit significativement à l'expérience. La cohérence des composants UI doit être adressée via un design system centralisé. L'intégrité des données (champs vides, IDs techniques exposés) doit être renforcée. Les axes Sécurité, Performance et Architecture nécessitent un audit technique approfondi. L'application Tracker présente une base solide. Les problèmes identifiés sont corrigeables sans refonte architecturale majeure. Un plan de sprints structuré permettra d'atteindre un niveau de qualité production élevé en 2 à 4 mois.
